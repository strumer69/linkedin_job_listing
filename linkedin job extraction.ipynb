{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39ecaf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a494723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = {\"usa\": {\"onsite\":\"https://www.linkedin.com/jobs/search/?currentJobId=3351674810&f_WT=1&geoId=103644278&keywords=data%20analyst&location=United%20States&refresh=true&start=\",\n",
    "                 \"remote\": \"https://www.linkedin.com/jobs/search/?currentJobId=3205250146&f_WRA=true&f_WT=2&geoId=103644278&keywords=data%20analyst&location=United%20States&refresh=true&start=\",\n",
    "                 \"hybrid\": \"https://www.linkedin.com/jobs/search/?currentJobId=3343518868&f_WRA=true&f_WT=3&geoId=103644278&keywords=data%20analyst&location=United%20States&refresh=true&start=\"},\n",
    "         \n",
    "        \"canada\":{\"onsite\": \"https://www.linkedin.com/jobs/search/?currentJobId=3223346796&f_WT=1&geoId=101174742&keywords=data%20analyst&location=Canada&refresh=true&start=\",\n",
    "                  \"remote\":\"https://www.linkedin.com/jobs/search/?currentJobId=3335580667&f_WT=2&geoId=101174742&keywords=data%20analyst&location=Canada&refresh=true&start=\",\n",
    "                  \"hybrid\":\"https://www.linkedin.com/jobs/search/?currentJobId=3335356174&f_WT=3&geoId=101174742&keywords=data%20analyst&location=Canada&refresh=true&start=\"},\n",
    "        \n",
    "         \"africa\": {\"onsite\":\"https://www.linkedin.com/jobs/search/?currentJobId=3364254624&f_WT=1&geoId=103537801&keywords=data%20analyst&location=Africa&refresh=true&start=\",\n",
    "                    \"remote\":\"https://www.linkedin.com/jobs/search/?currentJobId=3357561865&f_WT=2&geoId=103537801&keywords=data%20analyst&location=Africa&refresh=true&start=\",\n",
    "                    \"hybrid\":\"https://www.linkedin.com/jobs/search/?currentJobId=3363788623&f_WT=3&geoId=103537801&keywords=data%20analyst&location=Africa&refresh=true&start=\"}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b6077445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['usa', 'canada', 'africa'])\n"
     ]
    }
   ],
   "source": [
    "print(links.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f225725a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usa\n",
      "canada\n",
      "africa\n"
     ]
    }
   ],
   "source": [
    "for i in links:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512e532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to scrap job listings\n",
    "def create_job_csv(country_links: dict, country: str):\n",
    "    \n",
    "    # create file or open file in write mode\n",
    "    with open('linkedin-jobs-'+country+'.csv', mode='w', encoding='UTF-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # columns extracted\n",
    "        writer.writerow(['title', 'company', 'description', 'onsite_remote',\n",
    "                        'salary', 'location', 'criteria', 'posted_date', 'link'])\n",
    "\n",
    "        \n",
    "        #  \n",
    "        \n",
    "        def linkedin_scraper(webpage, page_number, onsite_remote):\n",
    "            count = 0\n",
    "            next_page = webpage + str(page_number)\n",
    "            \n",
    "            response = requests.get(str(next_page))\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            # print(response.content)\n",
    "            \n",
    "            jobs = soup.find_all(\n",
    "                'div', class_='base-card relative w-full hover:no-underline focus:no-underline base-card--link base-search-card base-search-card--link job-search-card')\n",
    "            \n",
    "            for job in jobs:\n",
    "                job_criteria = []\n",
    "                \n",
    "                job_title = job.find(\n",
    "                    'h3', class_='base-search-card__title').text.strip()\n",
    "                \n",
    "                job_company = job.find(\n",
    "                    'h4', class_='base-search-card__subtitle').text.strip()\n",
    "                \n",
    "                job_location = job.find(\n",
    "                    'span', class_='job-search-card__location').text.strip()\n",
    "                \n",
    "                job_datetime = job.find(\n",
    "                    'time', class_='job-search-card__listdate')['datetime'] if job.find(\n",
    "                    'time', class_='job-search-card__listdate') is not None else job.find(\n",
    "                    'time', class_='job-search-card__listdate--new')['datetime']\n",
    "                \n",
    "                job_salary = job.find('span', class_='job-search-card__salary-info').text.strip(\n",
    "                ) if job.find('span', class_='job-search-card__salary-info') is not None else \"NaN\"\n",
    "\n",
    "                job_link = job.find('a', class_='base-card__full-link')['href']\n",
    "                \n",
    "                \n",
    "                resp = requests.get(job_link)\n",
    "                sp = BeautifulSoup(resp.content, 'html.parser')\n",
    "\n",
    "                # Save requests as html pages to help view classes for scraping\n",
    "                #---------------------------------------------------------------------- only in africa\n",
    "                if count == 0 and country == 'africa':\n",
    "                    with open('scrap_page_view/job-list.html', mode='w', encoding=\"utf-8\") as job_list:\n",
    "                        job_list.write(str(response.content))\n",
    "                        job_list.close()\n",
    "                    with open('scrap_page_view/job.html', mode='w', encoding=\"utf-8\") as job_detail:\n",
    "                        job_detail.write(str(resp.content))\n",
    "                        job_detail.close()\n",
    "                count += 1\n",
    "                #----------------------------------------------------------------------\n",
    "\n",
    "                job_desc = sp.find('div', class_='show-more-less-html__markup show-more-less-html__markup--clamp-after-5').text.strip(\n",
    "                ) if sp.find('div', class_='show-more-less-html__markup show-more-less-html__markup--clamp-after-5') is not None else \"Nan\"\n",
    "\n",
    "                #----------------------------------------------------------------------criteria\n",
    "                criteria = sp.find_all(\n",
    "                    'li', class_='description__job-criteria-item')\n",
    "                for criterion in criteria:\n",
    "                    feature = criterion.find(\n",
    "                        'h3', class_='description__job-criteria-subheader').text.strip()\n",
    "                    value = criterion.find(\n",
    "                        'span', class_='description__job-criteria-text description__job-criteria-text--criteria').text.strip()\n",
    "                    job_criteria.append({feature: value})\n",
    "                    \n",
    "                #----------------------------------------------------------------------update row of excel\n",
    "\n",
    "                writer.writerow([job_title, job_company, job_desc, onsite_remote, job_salary,\n",
    "                                job_location, job_criteria, job_datetime, job_link])\n",
    "                print(' Data updated')\n",
    "                \n",
    "                #----------------------------------------------------------------------\n",
    "                \n",
    "            #---------------------------------------- Move to the next page \n",
    "            if page_number < 24:\n",
    "                \n",
    "                page_number = page_number + 25\n",
    "                linkedin_scraper(webpage, page_number, onsite_remote)\n",
    "            #---------------------------------------\n",
    "\n",
    "            \n",
    "        #-------------------------------------------------------------------------\n",
    "        for work_type in country_links:\n",
    "            linkedin_scraper(country_links[work_type], 0, work_type)\n",
    "        #-------------------------------------------------------------------------\n",
    "\n",
    "        \n",
    "# simply just call the create_job_csv function.\n",
    "for country in links:\n",
    "    create_job_csv(links[country], country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa987c30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
